{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162c8d04",
   "metadata": {},
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c028b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed32e0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Lammatized</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charger not working...ðŸ˜«</td>\n",
       "      <td>charger working</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one of the speaker doesn't works</td>\n",
       "      <td>one speaker work</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The piece i got is Worst piece and it is refur...</td>\n",
       "      <td>piece got worst piece refurbished lot feature ...</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awesome phone with really great look and perfo...</td>\n",
       "      <td>awesome phone really great look performance lo...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  \\\n",
       "0                                                Bad   \n",
       "1                            Charger not working...ðŸ˜«   \n",
       "2                   one of the speaker doesn't works   \n",
       "3  The piece i got is Worst piece and it is refur...   \n",
       "4  awesome phone with really great look and perfo...   \n",
       "\n",
       "                                          Lammatized  polarity sentiment  \n",
       "0                                                bad     -0.70  Negative  \n",
       "1                                    charger working      0.00   Neutral  \n",
       "2                                   one speaker work      0.00   Neutral  \n",
       "3  piece got worst piece refurbished lot feature ...     -0.31  Negative  \n",
       "4  awesome phone really great look performance lo...      0.58  Positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Final_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4db97",
   "metadata": {},
   "source": [
    "# Convert our sentiment in numeric form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6b2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6d442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "data['sentiment_label'] = labelencoder.fit_transform(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9c69f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Lammatized</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charger not working...ðŸ˜«</td>\n",
       "      <td>charger working</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one of the speaker doesn't works</td>\n",
       "      <td>one speaker work</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The piece i got is Worst piece and it is refur...</td>\n",
       "      <td>piece got worst piece refurbished lot feature ...</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awesome phone with really great look and perfo...</td>\n",
       "      <td>awesome phone really great look performance lo...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  \\\n",
       "0                                                Bad   \n",
       "1                            Charger not working...ðŸ˜«   \n",
       "2                   one of the speaker doesn't works   \n",
       "3  The piece i got is Worst piece and it is refur...   \n",
       "4  awesome phone with really great look and perfo...   \n",
       "\n",
       "                                          Lammatized  polarity sentiment  \\\n",
       "0                                                bad     -0.70  Negative   \n",
       "1                                    charger working      0.00   Neutral   \n",
       "2                                   one speaker work      0.00   Neutral   \n",
       "3  piece got worst piece refurbished lot feature ...     -0.31  Negative   \n",
       "4  awesome phone really great look performance lo...      0.58  Positive   \n",
       "\n",
       "   sentiment_label  \n",
       "0                0  \n",
       "1                1  \n",
       "2                1  \n",
       "3                0  \n",
       "4                2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aeb5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative = 0\n",
    "# Neutral = 1\n",
    "# Positive = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac5b1e",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f328ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd9bec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer()\n",
    "bow = bow_vectorizer.fit_transform(data['Lammatized'].apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f154260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff36f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bow.toarray()\n",
    "y = data['sentiment_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74318cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7fad3",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287cd9b2",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53b25a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9942acc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Testing Accuracy*************\n",
      "confusion_matrix \n",
      " [[ 426   84  105]\n",
      " [   5 1119   36]\n",
      " [  51   96 2921]]\n",
      "*********************************************\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78       615\n",
      "           1       0.86      0.96      0.91      1160\n",
      "           2       0.95      0.95      0.95      3068\n",
      "\n",
      "    accuracy                           0.92      4843\n",
      "   macro avg       0.90      0.87      0.88      4843\n",
      "weighted avg       0.92      0.92      0.92      4843\n",
      "\n",
      "*********************************************\n",
      "Accuracy score \n",
      " 0.9221556886227545\n"
     ]
    }
   ],
   "source": [
    "model_1=LogisticRegression()\n",
    "\n",
    "# Trainning\n",
    "model_1.fit(x_train,y_train)\n",
    "# Testing\n",
    "y_pred_test_lr=model_1.predict(x_test)\n",
    "\n",
    "print('*************Testing Accuracy*************')\n",
    "print('confusion_matrix \\n',confusion_matrix(y_test,y_pred_test_lr))\n",
    "print('*********************************************')\n",
    "print('classification_report \\n',classification_report(y_test,y_pred_test_lr))\n",
    "print('*********************************************')\n",
    "print(\"Accuracy score \\n\",accuracy_score(y_test,y_pred_test_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e035f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Training Accuracy*************\n",
      "confusion_matrix \n",
      " [[1690   45   30]\n",
      " [   3 3471   17]\n",
      " [   4   33 9235]]\n",
      "*********************************************\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1765\n",
      "           1       0.98      0.99      0.99      3491\n",
      "           2       0.99      1.00      1.00      9272\n",
      "\n",
      "    accuracy                           0.99     14528\n",
      "   macro avg       0.99      0.98      0.99     14528\n",
      "weighted avg       0.99      0.99      0.99     14528\n",
      "\n",
      "*********************************************\n",
      "Accuracy score \n",
      " 0.9909140969162996\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "y_pred_train_lr = model_1.predict(x_train)\n",
    "\n",
    "print('*************Training Accuracy*************')\n",
    "print('confusion_matrix \\n',confusion_matrix(y_train,y_pred_train_lr))\n",
    "print('*********************************************')\n",
    "print('classification_report \\n',classification_report(y_train,y_pred_train_lr))\n",
    "print('*********************************************')\n",
    "print(\"Accuracy score \\n\",accuracy_score(y_train,y_pred_train_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecde6f",
   "metadata": {},
   "source": [
    "## 2. Linear support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a21e0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc1d5a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Testing Accuracy*************\n",
      "confusion_matrix \n",
      " [[ 480   49   86]\n",
      " [  11 1125   24]\n",
      " [  50   81 2937]]\n",
      "*********************************************\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       615\n",
      "           1       0.90      0.97      0.93      1160\n",
      "           2       0.96      0.96      0.96      3068\n",
      "\n",
      "    accuracy                           0.94      4843\n",
      "   macro avg       0.92      0.90      0.91      4843\n",
      "weighted avg       0.94      0.94      0.94      4843\n",
      "\n",
      "*********************************************\n",
      "Accuracy score \n",
      " 0.9378484410489366\n"
     ]
    }
   ],
   "source": [
    "model_2 = LinearSVC(verbose=0)\n",
    "\n",
    "# Trainning\n",
    "model_2.fit(x_train,y_train)\n",
    "# Testing\n",
    "y_pred_test_lsvc = model_2.predict(x_test)\n",
    "\n",
    "print('*************Testing Accuracy*************')\n",
    "print('confusion_matrix \\n',confusion_matrix(y_test,y_pred_test_lsvc))\n",
    "print('*********************************************')\n",
    "print('classification_report \\n',classification_report(y_test,y_pred_test_lsvc))\n",
    "print('*********************************************')\n",
    "print(\"Accuracy score \\n\",accuracy_score(y_test,y_pred_test_lsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eb4f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Training Accuracy*************\n",
      "confusion_matrix \n",
      " [[1763    0    2]\n",
      " [   0 3488    3]\n",
      " [   1    0 9271]]\n",
      "*********************************************\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1765\n",
      "           1       1.00      1.00      1.00      3491\n",
      "           2       1.00      1.00      1.00      9272\n",
      "\n",
      "    accuracy                           1.00     14528\n",
      "   macro avg       1.00      1.00      1.00     14528\n",
      "weighted avg       1.00      1.00      1.00     14528\n",
      "\n",
      "*********************************************\n",
      "Accuracy score \n",
      " 0.9995870044052864\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "y_pred_train_lsvc = model_2.predict(x_train)\n",
    "\n",
    "print('*************Training Accuracy*************')\n",
    "print('confusion_matrix \\n',confusion_matrix(y_train,y_pred_train_lsvc))\n",
    "print('*********************************************')\n",
    "print('classification_report \\n',classification_report(y_train,y_pred_train_lsvc))\n",
    "print('*********************************************')\n",
    "print(\"Accuracy score \\n\",accuracy_score(y_train,y_pred_train_lsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365eceb6",
   "metadata": {},
   "source": [
    "## 3. Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb95a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0672a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Testing Accuracy*************\n",
      "confusion_matrix \n",
      " [[ 331   96  188]\n",
      " [  42 1063   55]\n",
      " [ 142  110 2816]]\n",
      "*********************************************\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.59       615\n",
      "           1       0.84      0.92      0.88      1160\n",
      "           2       0.92      0.92      0.92      3068\n",
      "\n",
      "    accuracy                           0.87      4843\n",
      "   macro avg       0.80      0.79      0.79      4843\n",
      "weighted avg       0.87      0.87      0.87      4843\n",
      "\n",
      "*********************************************\n",
      "Accuracy score \n",
      " 0.8692958909766674\n"
     ]
    }
   ],
   "source": [
    "model_3 = DecisionTreeClassifier(criterion = 'entropy')\n",
    "\n",
    "# Trainning\n",
    "model_3.fit(x_train,y_train)\n",
    "# Testing\n",
    "y_pred_test_dtc = model_3.predict(x_test)\n",
    "\n",
    "print('*************Testing Accuracy*************')\n",
    "print('confusion_matrix \\n',confusion_matrix(y_test,y_pred_test_dtc))\n",
    "print('*********************************************')\n",
    "print('classification_report \\n',classification_report(y_test,y_pred_test_dtc))\n",
    "print('*********************************************')\n",
    "print(\"Accuracy score \\n\",accuracy_score(y_test,y_pred_test_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddcde81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Training Accuracy*************\n",
      "confusion_matrix \n",
      " [[1765    0    0]\n",
      " [   0 3491    0]\n",
      " [   0    0 9272]]\n",
      "*********************************************\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1765\n",
      "           1       1.00      1.00      1.00      3491\n",
      "           2       1.00      1.00      1.00      9272\n",
      "\n",
      "    accuracy                           1.00     14528\n",
      "   macro avg       1.00      1.00      1.00     14528\n",
      "weighted avg       1.00      1.00      1.00     14528\n",
      "\n",
      "*********************************************\n",
      "Accuracy score \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "y_pred_train_dtc = model_3.predict(x_train)           \n",
    "\n",
    "print('*************Training Accuracy*************')\n",
    "print('confusion_matrix \\n',confusion_matrix(y_train,y_pred_train_dtc))\n",
    "print('*********************************************')\n",
    "print('classification_report \\n',classification_report(y_train,y_pred_train_dtc))\n",
    "print('*********************************************')\n",
    "print(\"Accuracy score \\n\",accuracy_score(y_train,y_pred_train_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce5a0f",
   "metadata": {},
   "source": [
    "## 4. XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86f206d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b63768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:18:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "*************Testing Accuracy*************\n",
      "confusion_matrix \n",
      " [[ 449   52  114]\n",
      " [   6 1138   16]\n",
      " [  51   78 2939]]\n",
      "*********************************************\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80       615\n",
      "           1       0.90      0.98      0.94      1160\n",
      "           2       0.96      0.96      0.96      3068\n",
      "\n",
      "    accuracy                           0.93      4843\n",
      "   macro avg       0.91      0.89      0.90      4843\n",
      "weighted avg       0.93      0.93      0.93      4843\n",
      "\n",
      "*********************************************\n",
      "Accuracy score \n",
      " 0.9345447036960561\n"
     ]
    }
   ],
   "source": [
    "model_4 = XGBClassifier(learning_rate = 0.9)\n",
    "\n",
    "# Trainning\n",
    "model_4.fit(x_train,y_train)\n",
    "# Testing\n",
    "y_pred_test_xgbc = model_4.predict(x_test)\n",
    "\n",
    "print('*************Testing Accuracy*************')\n",
    "print('confusion_matrix \\n',confusion_matrix(y_test,y_pred_test_xgbc))\n",
    "print('*********************************************')\n",
    "print('classification_report \\n',classification_report(y_test,y_pred_test_xgbc))\n",
    "print('*********************************************')\n",
    "print(\"Accuracy score \\n\",accuracy_score(y_test,y_pred_test_xgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b63d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Training Accuracy*************\n",
      "confusion_matrix \n",
      " [[1640  103   22]\n",
      " [   6 3469   16]\n",
      " [  11  107 9154]]\n",
      "*********************************************\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      1765\n",
      "           1       0.94      0.99      0.97      3491\n",
      "           2       1.00      0.99      0.99      9272\n",
      "\n",
      "    accuracy                           0.98     14528\n",
      "   macro avg       0.98      0.97      0.97     14528\n",
      "weighted avg       0.98      0.98      0.98     14528\n",
      "\n",
      "*********************************************\n",
      "Accuracy score \n",
      " 0.9817593612334802\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "y_pred_train_xgbc = model_4.predict(x_train)           \n",
    "\n",
    "print('*************Training Accuracy*************')\n",
    "print('confusion_matrix \\n',confusion_matrix(y_train,y_pred_train_xgbc))\n",
    "print('*********************************************')\n",
    "print('classification_report \\n',classification_report(y_train,y_pred_train_xgbc))\n",
    "print('*********************************************')\n",
    "print(\"Accuracy score \\n\",accuracy_score(y_train,y_pred_train_xgbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa610c",
   "metadata": {},
   "source": [
    "## Accuracy comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46d4a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['Linear Regression','Linear SVC','Decision Tree','XGB Classifier']\n",
    "\n",
    "training = [\n",
    "    (accuracy_score(y_train,y_pred_train_lr)*100),\n",
    "    (accuracy_score(y_train,y_pred_train_lsvc)*100),\n",
    "    (accuracy_score(y_train,y_pred_train_dtc)*100),\n",
    "    (accuracy_score(y_train,y_pred_train_xgbc)*100)\n",
    "]\n",
    "\n",
    "testing = [\n",
    "    (accuracy_score(y_test,y_pred_test_lr)*100),\n",
    "    (accuracy_score(y_test,y_pred_test_lsvc)*100),\n",
    "    (accuracy_score(y_test,y_pred_test_dtc)*100),\n",
    "    (accuracy_score(y_test,y_pred_test_xgbc)*100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b447601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training</th>\n",
       "      <th>Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>99.091410</td>\n",
       "      <td>92.215569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>99.958700</td>\n",
       "      <td>93.784844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>86.929589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>98.175936</td>\n",
       "      <td>93.454470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    Training    Testing\n",
       "0  Linear Regression   99.091410  92.215569\n",
       "1         Linear SVC   99.958700  93.784844\n",
       "2      Decision Tree  100.000000  86.929589\n",
       "3     XGB Classifier   98.175936  93.454470"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Model'] = model\n",
    "df['Training'] = training\n",
    "df['Testing'] = testing\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69efd3",
   "metadata": {},
   "source": [
    "### Here Linear SVC model Better than other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27906e",
   "metadata": {},
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af91cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d0e81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('CountVectorizer',bow_vectorizer),('clf',model_2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "336c7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'final_model.pkl'\n",
    "pickle.dump(pipeline,open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11bd25d",
   "metadata": {},
   "source": [
    "### Top five most negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7db79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11fe78a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18589   -1.0\n",
       "6765    -1.0\n",
       "7308    -1.0\n",
       "1462    -1.0\n",
       "10383   -1.0\n",
       "        ... \n",
       "7007     1.0\n",
       "11851    1.0\n",
       "11837    1.0\n",
       "6170     1.0\n",
       "9014     1.0\n",
       "Name: polarity, Length: 19371, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['polarity'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "662b9d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18589                                                                                 worst... get a samsung\n",
       "6765                                                                                            Worst mobile\n",
       "7308                                                                            it has a horrible selfie cam\n",
       "1462     Terrible battery life and camera. Use my phone as my camera but this was the reason I switched. ...\n",
       "10383                               I did that with tooth paste but nothing improves in fact i becomes worst\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Reviews'].iloc[[18589,6765,7308,1462,10383]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3b991",
   "metadata": {},
   "source": [
    "### Top five most positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19f0a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10781    1.0\n",
       "14969    1.0\n",
       "5792     1.0\n",
       "5793     1.0\n",
       "11028    1.0\n",
       "        ... \n",
       "15694   -1.0\n",
       "6461    -1.0\n",
       "6765    -1.0\n",
       "9180    -1.0\n",
       "6498    -1.0\n",
       "Name: polarity, Length: 19371, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['polarity'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce15a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10781                                                                    definetly 4s... the best.\n",
       "14969    So how would you describe other phones battery life since iphone is the BEST in its class\n",
       "5792                                                                           An awesome. Product\n",
       "5793                                                                             Excellent product\n",
       "11028                                                                               best option 4s\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Reviews'].iloc[[10781,14969,5792,5793,11028]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b508c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
